{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7XHyeWRn1SA"
      },
      "outputs": [],
      "source": [
        "from numpy import expand_dims\n",
        "from numpy import mean\n",
        "from numpy import ones\n",
        "from numpy.random import randn\n",
        "from numpy.random import randint\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.datasets.mnist import load_data\n",
        "from tensorflow.keras import backend\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Reshape\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.constraints import Constraint\n",
        "from matplotlib import pyplot\n",
        " \n",
        "# clip model weights to a given hypercube\n",
        "\n",
        " \n",
        "# calculate wasserstein loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ClipConstraint(Constraint):\n",
        "\t# set clip value when initialized\n",
        "\tdef __init__(self, clip_value):\n",
        "\t\tself.clip_value = clip_value\n",
        " \n",
        "\t# clip model weights to hypercube\n",
        "\tdef __call__(self, weights):\n",
        "\t\treturn backend.clip(weights, -self.clip_value, self.clip_value)\n",
        " \n",
        "\t# get the config\n",
        "\tdef get_config(self):\n",
        "\t\treturn {'clip_value': self.clip_value}"
      ],
      "metadata": {
        "id": "DMlvdmVjn1-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def wasserstein_loss(y_true, y_pred):\n",
        "\treturn backend.mean(y_true * y_pred)\n"
      ],
      "metadata": {
        "id": "5LD-YgsKn8_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_critic(in_shape=(28,28,1)):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# weight constraint\n",
        "\tconst = ClipConstraint(0.01)\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# downsample to 14x14\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const, input_shape=in_shape))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# downsample to 7x7\n",
        "\tmodel.add(Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init, kernel_constraint=const))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# scoring, linear activation\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(1))\n",
        "\t# compile model\n",
        "\topt = RMSprop(lr=0.00005)\n",
        "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
        "\treturn model\n",
        "\n",
        "# define the standalone generator model\n",
        "def define_generator(latent_dim):\n",
        "\t# weight initialization\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\t# define model\n",
        "\tmodel = Sequential()\n",
        "\t# foundation for 7x7 image\n",
        "\tn_nodes = 128 * 7 * 7\n",
        "\tmodel.add(Dense(n_nodes, kernel_initializer=init, input_dim=latent_dim))\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\tmodel.add(Reshape((7, 7, 128)))\n",
        "\t# upsample to 14x14\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# upsample to 28x28\n",
        "\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(LeakyReLU(alpha=0.2))\n",
        "\t# output 28x28x1\n",
        "\tmodel.add(Conv2D(1, (7,7), activation='tanh', padding='same', kernel_initializer=init))\n",
        "\treturn model\n",
        "\n",
        "# define the combined generator and critic model, for updating the generator\n",
        "def define_gan(generator, critic):\n",
        "\t# make weights in the critic not trainable\n",
        "\tfor layer in critic.layers:\n",
        "\t\tif not isinstance(layer, BatchNormalization):\n",
        "\t\t\tlayer.trainable = False\n",
        "\t# connect them\n",
        "\tmodel = Sequential()\n",
        "\t# add generator\n",
        "\tmodel.add(generator)\n",
        "\t# add the critic\n",
        "\tmodel.add(critic)\n",
        "\t# compile model\n",
        "\topt = RMSprop(lr=0.00005)\n",
        "\tmodel.compile(loss=wasserstein_loss, optimizer=opt)\n",
        "\treturn model\n",
        "\n",
        "# load images\n",
        "def load_real_samples():\n",
        "\t# load dataset\n",
        "\t(trainX, trainy), (_, _) = load_data()\n",
        "\t# select all of the examples for a given class\n",
        "\tselected_ix = trainy == 7\n",
        "\tX = trainX[selected_ix]\n",
        "\t# expand to 3d, e.g. add channels\n",
        "\tX = expand_dims(X, axis=-1)\n",
        "\t# convert from ints to floats\n",
        "\tX = X.astype('float32')\n",
        "\t# scale from [0,255] to [-1,1]\n",
        "\tX = (X - 127.5) / 127.5\n",
        "\treturn X\n",
        "\n",
        "# select real samples\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "\t# choose random instances\n",
        "\tix = randint(0, dataset.shape[0], n_samples)\n",
        "\t# select images\n",
        "\tX = dataset[ix]\n",
        "\t# generate class labels, -1 for 'real'\n",
        "\ty = -ones((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# generate points in latent space as input for the generator\n",
        "def generate_latent_points(latent_dim, n_samples):\n",
        "\t# generate points in the latent space\n",
        "\tx_input = randn(latent_dim * n_samples)\n",
        "\t# reshape into a batch of inputs for the network\n",
        "\tx_input = x_input.reshape(n_samples, latent_dim)\n",
        "\treturn x_input\n",
        "\n",
        "# use the generator to generate n fake examples, with class labels\n",
        "def generate_fake_samples(generator, latent_dim, n_samples):\n",
        "\t# generate points in latent space\n",
        "\tx_input = generate_latent_points(latent_dim, n_samples)\n",
        "\t# predict outputs\n",
        "\tX = generator.predict(x_input)\n",
        "\t# create class labels with 1.0 for 'fake'\n",
        "\ty = ones((n_samples, 1))\n",
        "\treturn X, y\n",
        "\n",
        "# generate samples and save as a plot and save the model\n",
        "def summarize_performance(step, g_model, latent_dim, n_samples=100):\n",
        "\t# prepare fake examples\n",
        "\tX, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n",
        "\t# scale from [-1,1] to [0,1]\n",
        "\tX = (X + 1) / 2.0\n",
        "\t# plot images\n",
        "\tfor i in range(10 * 10):\n",
        "\t\t# define subplot\n",
        "\t\tpyplot.subplot(10, 10, 1 + i)\n",
        "\t\t# turn off axis\n",
        "\t\tpyplot.axis('off')\n",
        "\t\t# plot raw pixel data\n",
        "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray_r')\n",
        "\t# save plot to file\n",
        "\tfilename1 = 'generated_plot_%04d.png' % (step+1)\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\t# save the generator model\n",
        "\tfilename2 = 'model_%04d.h5' % (step+1)\n",
        "\tg_model.save(filename2)\n",
        "\tprint('>Saved: %s and %s' % (filename1, filename2))\n",
        "\n",
        "# create a line plot of loss for the gan and save to file\n",
        "def plot_history(d1_hist, d2_hist, g_hist):\n",
        "\t# plot history\n",
        "\tpyplot.plot(d1_hist, label='crit_real')\n",
        "\tpyplot.plot(d2_hist, label='crit_fake')\n",
        "\tpyplot.plot(g_hist, label='gen')\n",
        "\tpyplot.legend()\n",
        "\tpyplot.savefig('plot_line_plot_loss.png')\n",
        "\tpyplot.close()\n",
        "\n",
        "# train the generator and critic\n",
        "def train(g_model, c_model, gan_model, dataset, latent_dim, n_epochs=10, n_batch=64, n_critic=5):\n",
        "\t# calculate the number of batches per training epoch\n",
        "\tbat_per_epo = int(dataset.shape[0] / n_batch)\n",
        "\t# calculate the number of training iterations\n",
        "\tn_steps = bat_per_epo * n_epochs\n",
        "\t# calculate the size of half a batch of samples\n",
        "\thalf_batch = int(n_batch / 2)\n",
        "\t# lists for keeping track of loss\n",
        "\tc1_hist, c2_hist, g_hist = list(), list(), list()\n",
        "\t# manually enumerate epochs\n",
        "\tfor i in range(n_steps):\n",
        "\t\t# update the critic more than the generator\n",
        "\t\tc1_tmp, c2_tmp = list(), list()\n",
        "\t\tfor _ in range(n_critic):\n",
        "\t\t\t# get randomly selected 'real' samples\n",
        "\t\t\tX_real, y_real = generate_real_samples(dataset, half_batch)\n",
        "\t\t\t# update critic model weights\n",
        "\t\t\tc_loss1 = c_model.train_on_batch(X_real, y_real)\n",
        "\t\t\tc1_tmp.append(c_loss1)\n",
        "\t\t\t# generate 'fake' examples\n",
        "\t\t\tX_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
        "\t\t\t# update critic model weights\n",
        "\t\t\tc_loss2 = c_model.train_on_batch(X_fake, y_fake)\n",
        "\t\t\tc2_tmp.append(c_loss2)\n",
        "\t\t# store critic loss\n",
        "\t\tc1_hist.append(mean(c1_tmp))\n",
        "\t\tc2_hist.append(mean(c2_tmp))\n",
        "\t\t# prepare points in latent space as input for the generator\n",
        "\t\tX_gan = generate_latent_points(latent_dim, n_batch)\n",
        "\t\t# create inverted labels for the fake samples\n",
        "\t\ty_gan = -ones((n_batch, 1))\n",
        "\t\t# update the generator via the critic's error\n",
        "\t\tg_loss = gan_model.train_on_batch(X_gan, y_gan)\n",
        "\t\tg_hist.append(g_loss)\n",
        "\t\t# summarize loss on this batch\n",
        "\t\tprint('>%d, c1=%.3f, c2=%.3f g=%.3f' % (i+1, c1_hist[-1], c2_hist[-1], g_loss))\n",
        "\t\t# evaluate the model performance every 'epoch'\n",
        "\t\tif (i+1) % bat_per_epo == 0:\n",
        "\t\t\tsummarize_performance(i, g_model, latent_dim)\n",
        "\t# line plots of loss\n",
        "\tplot_history(c1_hist, c2_hist, g_hist)"
      ],
      "metadata": {
        "id": "z04EbD1PpT_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "latent_dim = 50\n",
        "# create the critic\n",
        "critic = define_critic()\n",
        "# create the generator\n",
        "generator = define_generator(latent_dim)\n",
        "# create the gan\n",
        "gan_model = define_gan(generator, critic)\n",
        "# load image data\n",
        "dataset = load_real_samples()\n",
        "print(dataset.shape)\n",
        "# train model\n",
        "train(generator, critic, gan_model, dataset, latent_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mz7W2hhbpZau",
        "outputId": "42b1a816-1a60-42bd-f68f-0cada1256200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/rmsprop.py:130: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(RMSprop, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(6265, 28, 28, 1)\n",
            ">1, c1=-2.375, c2=0.042 g=-0.646\n",
            ">2, c1=-6.617, c2=0.122 g=-2.157\n",
            ">3, c1=-9.605, c2=0.182 g=-3.103\n",
            ">4, c1=-11.926, c2=0.251 g=-3.911\n",
            ">5, c1=-14.558, c2=0.304 g=-4.998\n",
            ">6, c1=-16.003, c2=0.386 g=-6.174\n",
            ">7, c1=-17.631, c2=0.457 g=-7.079\n",
            ">8, c1=-18.846, c2=0.527 g=-8.649\n",
            ">9, c1=-20.386, c2=0.622 g=-10.074\n",
            ">10, c1=-21.648, c2=0.702 g=-11.126\n",
            ">11, c1=-22.239, c2=0.772 g=-12.077\n",
            ">12, c1=-23.491, c2=0.870 g=-13.441\n",
            ">13, c1=-24.527, c2=0.971 g=-13.978\n",
            ">14, c1=-25.545, c2=1.052 g=-14.880\n",
            ">15, c1=-26.264, c2=1.172 g=-15.446\n",
            ">16, c1=-26.920, c2=1.232 g=-16.030\n",
            ">17, c1=-27.437, c2=1.330 g=-16.698\n",
            ">18, c1=-27.766, c2=1.439 g=-17.136\n",
            ">19, c1=-29.410, c2=1.476 g=-17.840\n",
            ">20, c1=-29.253, c2=1.481 g=-18.464\n",
            ">21, c1=-30.441, c2=1.600 g=-18.719\n",
            ">22, c1=-30.966, c2=1.594 g=-19.119\n",
            ">23, c1=-31.253, c2=1.663 g=-19.511\n",
            ">24, c1=-31.894, c2=1.595 g=-20.450\n",
            ">25, c1=-32.384, c2=1.624 g=-19.815\n",
            ">26, c1=-32.788, c2=1.590 g=-20.517\n",
            ">27, c1=-32.888, c2=1.580 g=-21.645\n",
            ">28, c1=-33.741, c2=1.539 g=-22.294\n",
            ">29, c1=-34.335, c2=1.305 g=-22.732\n",
            ">30, c1=-34.731, c2=1.161 g=-23.218\n",
            ">31, c1=-35.375, c2=0.851 g=-23.883\n",
            ">32, c1=-36.244, c2=0.524 g=-24.244\n",
            ">33, c1=-36.348, c2=0.013 g=-24.403\n",
            ">34, c1=-36.503, c2=-0.502 g=-24.923\n",
            ">35, c1=-37.124, c2=-1.228 g=-25.796\n",
            ">36, c1=-38.045, c2=-1.968 g=-25.865\n",
            ">37, c1=-38.360, c2=-2.655 g=-25.920\n",
            ">38, c1=-39.103, c2=-3.721 g=-26.859\n",
            ">39, c1=-38.573, c2=-4.555 g=-28.210\n",
            ">40, c1=-39.719, c2=-5.818 g=-29.401\n",
            ">41, c1=-39.635, c2=-6.782 g=-29.465\n",
            ">42, c1=-40.023, c2=-8.130 g=-31.056\n",
            ">43, c1=-40.949, c2=-9.180 g=-31.260\n",
            ">44, c1=-41.407, c2=-10.633 g=-32.036\n",
            ">45, c1=-41.911, c2=-12.202 g=-31.789\n",
            ">46, c1=-42.646, c2=-13.318 g=-33.736\n",
            ">47, c1=-43.204, c2=-15.025 g=-33.759\n",
            ">48, c1=-42.873, c2=-16.115 g=-34.871\n",
            ">49, c1=-44.453, c2=-18.033 g=-34.438\n",
            ">50, c1=-44.763, c2=-19.527 g=-35.465\n",
            ">51, c1=-45.103, c2=-20.902 g=-36.558\n",
            ">52, c1=-46.342, c2=-22.246 g=-37.032\n",
            ">53, c1=-46.097, c2=-23.399 g=-37.804\n",
            ">54, c1=-47.041, c2=-24.874 g=-39.472\n",
            ">55, c1=-47.655, c2=-26.156 g=-40.443\n",
            ">56, c1=-48.562, c2=-27.378 g=-40.670\n",
            ">57, c1=-48.813, c2=-28.448 g=-41.491\n",
            ">58, c1=-48.727, c2=-29.681 g=-42.764\n",
            ">59, c1=-49.647, c2=-30.726 g=-44.341\n",
            ">60, c1=-50.914, c2=-31.740 g=-44.149\n",
            ">61, c1=-51.192, c2=-32.709 g=-45.028\n",
            ">62, c1=-51.389, c2=-33.837 g=-45.749\n",
            ">63, c1=-52.072, c2=-34.659 g=-46.618\n",
            ">64, c1=-52.235, c2=-35.943 g=-47.761\n",
            ">65, c1=-53.982, c2=-36.475 g=-48.289\n",
            ">66, c1=-54.528, c2=-37.854 g=-48.658\n",
            ">67, c1=-54.204, c2=-38.282 g=-50.010\n",
            ">68, c1=-55.964, c2=-39.426 g=-50.648\n",
            ">69, c1=-56.622, c2=-40.288 g=-51.259\n",
            ">70, c1=-56.895, c2=-41.085 g=-52.201\n",
            ">71, c1=-57.698, c2=-42.094 g=-53.061\n",
            ">72, c1=-58.227, c2=-42.669 g=-53.880\n",
            ">73, c1=-59.487, c2=-43.757 g=-54.891\n",
            ">74, c1=-58.785, c2=-44.343 g=-55.264\n",
            ">75, c1=-60.518, c2=-45.479 g=-55.934\n",
            ">76, c1=-60.677, c2=-46.011 g=-56.571\n",
            ">77, c1=-61.430, c2=-47.153 g=-57.259\n",
            ">78, c1=-62.107, c2=-47.619 g=-58.430\n",
            ">79, c1=-63.330, c2=-48.640 g=-59.525\n",
            ">80, c1=-62.953, c2=-49.259 g=-60.051\n",
            ">81, c1=-64.066, c2=-50.209 g=-60.765\n",
            ">82, c1=-64.365, c2=-50.869 g=-61.571\n",
            ">83, c1=-65.769, c2=-51.925 g=-62.630\n",
            ">84, c1=-66.223, c2=-52.275 g=-63.079\n",
            ">85, c1=-66.568, c2=-53.438 g=-64.198\n",
            ">86, c1=-67.915, c2=-53.724 g=-64.395\n",
            ">87, c1=-68.337, c2=-55.003 g=-65.265\n",
            ">88, c1=-69.160, c2=-55.359 g=-65.815\n",
            ">89, c1=-69.838, c2=-56.483 g=-66.996\n",
            ">90, c1=-69.552, c2=-56.909 g=-67.525\n",
            ">91, c1=-70.936, c2=-57.870 g=-68.301\n",
            ">92, c1=-72.107, c2=-58.504 g=-69.051\n",
            ">93, c1=-72.234, c2=-59.304 g=-70.307\n",
            ">94, c1=-73.581, c2=-60.071 g=-70.940\n",
            ">95, c1=-73.346, c2=-60.657 g=-71.441\n",
            ">96, c1=-74.429, c2=-61.739 g=-72.258\n",
            ">97, c1=-75.116, c2=-62.082 g=-73.973\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0097.png and model_0097.h5\n",
            ">98, c1=-75.059, c2=-63.336 g=-74.367\n",
            ">99, c1=-76.576, c2=-63.731 g=-74.940\n",
            ">100, c1=-77.661, c2=-64.858 g=-75.759\n",
            ">101, c1=-77.880, c2=-65.315 g=-75.862\n",
            ">102, c1=-79.036, c2=-66.461 g=-77.032\n",
            ">103, c1=-78.765, c2=-66.887 g=-77.987\n",
            ">104, c1=-80.026, c2=-67.769 g=-78.926\n",
            ">105, c1=-81.065, c2=-68.248 g=-79.712\n",
            ">106, c1=-81.759, c2=-69.338 g=-80.642\n",
            ">107, c1=-81.363, c2=-69.720 g=-81.415\n",
            ">108, c1=-83.264, c2=-70.927 g=-81.897\n",
            ">109, c1=-83.506, c2=-71.491 g=-83.354\n",
            ">110, c1=-83.867, c2=-72.374 g=-83.661\n",
            ">111, c1=-85.137, c2=-72.900 g=-84.466\n",
            ">112, c1=-85.286, c2=-74.006 g=-85.456\n",
            ">113, c1=-86.365, c2=-74.533 g=-86.149\n",
            ">114, c1=-87.403, c2=-75.580 g=-86.964\n",
            ">115, c1=-87.712, c2=-76.348 g=-87.616\n",
            ">116, c1=-87.944, c2=-76.977 g=-88.747\n",
            ">117, c1=-88.964, c2=-77.864 g=-89.561\n",
            ">118, c1=-89.955, c2=-78.312 g=-90.653\n",
            ">119, c1=-90.884, c2=-79.434 g=-91.852\n",
            ">120, c1=-91.547, c2=-80.010 g=-92.081\n",
            ">121, c1=-91.359, c2=-81.115 g=-92.713\n",
            ">122, c1=-92.233, c2=-81.426 g=-94.088\n",
            ">123, c1=-93.677, c2=-82.506 g=-94.958\n",
            ">124, c1=-94.330, c2=-83.124 g=-94.810\n",
            ">125, c1=-94.107, c2=-84.328 g=-96.059\n",
            ">126, c1=-95.694, c2=-84.894 g=-97.695\n",
            ">127, c1=-95.771, c2=-85.639 g=-97.483\n",
            ">128, c1=-95.733, c2=-86.498 g=-99.143\n",
            ">129, c1=-98.116, c2=-87.234 g=-100.102\n",
            ">130, c1=-98.134, c2=-87.638 g=-100.275\n",
            ">131, c1=-98.851, c2=-88.931 g=-101.643\n",
            ">132, c1=-100.106, c2=-89.367 g=-102.816\n",
            ">133, c1=-99.954, c2=-90.462 g=-103.231\n",
            ">134, c1=-100.958, c2=-91.401 g=-103.774\n",
            ">135, c1=-102.372, c2=-91.571 g=-105.504\n",
            ">136, c1=-101.991, c2=-92.528 g=-105.706\n",
            ">137, c1=-101.727, c2=-93.479 g=-106.966\n",
            ">138, c1=-103.817, c2=-93.979 g=-107.497\n",
            ">139, c1=-105.589, c2=-95.065 g=-108.835\n",
            ">140, c1=-106.231, c2=-95.778 g=-109.570\n",
            ">141, c1=-105.259, c2=-96.470 g=-109.657\n",
            ">142, c1=-107.288, c2=-97.418 g=-110.902\n",
            ">143, c1=-108.013, c2=-98.296 g=-111.961\n",
            ">144, c1=-109.084, c2=-98.538 g=-112.835\n",
            ">145, c1=-109.023, c2=-99.805 g=-113.901\n",
            ">146, c1=-110.516, c2=-100.217 g=-115.095\n",
            ">147, c1=-110.528, c2=-101.352 g=-115.722\n",
            ">148, c1=-111.864, c2=-102.196 g=-116.433\n",
            ">149, c1=-112.933, c2=-102.889 g=-117.244\n",
            ">150, c1=-113.371, c2=-103.571 g=-118.453\n",
            ">151, c1=-113.760, c2=-104.302 g=-118.511\n",
            ">152, c1=-114.504, c2=-105.501 g=-119.880\n",
            ">153, c1=-115.163, c2=-105.920 g=-120.333\n",
            ">154, c1=-116.581, c2=-106.870 g=-121.634\n",
            ">155, c1=-116.281, c2=-107.189 g=-122.735\n",
            ">156, c1=-118.180, c2=-108.379 g=-123.357\n",
            ">157, c1=-118.185, c2=-108.960 g=-123.851\n",
            ">158, c1=-118.683, c2=-110.218 g=-124.541\n",
            ">159, c1=-120.122, c2=-111.366 g=-125.540\n",
            ">160, c1=-120.007, c2=-111.458 g=-125.863\n",
            ">161, c1=-121.822, c2=-112.868 g=-127.685\n",
            ">162, c1=-122.342, c2=-112.961 g=-128.682\n",
            ">163, c1=-122.756, c2=-113.985 g=-129.467\n",
            ">164, c1=-125.095, c2=-114.703 g=-130.435\n",
            ">165, c1=-125.034, c2=-115.596 g=-131.286\n",
            ">166, c1=-125.345, c2=-116.516 g=-132.210\n",
            ">167, c1=-125.475, c2=-117.149 g=-132.265\n",
            ">168, c1=-126.098, c2=-118.334 g=-133.457\n",
            ">169, c1=-127.226, c2=-118.479 g=-134.468\n",
            ">170, c1=-128.513, c2=-119.534 g=-134.862\n",
            ">171, c1=-129.233, c2=-120.761 g=-136.352\n",
            ">172, c1=-129.932, c2=-120.872 g=-137.350\n",
            ">173, c1=-131.328, c2=-121.681 g=-137.601\n",
            ">174, c1=-132.159, c2=-123.030 g=-138.988\n",
            ">175, c1=-131.951, c2=-123.664 g=-139.870\n",
            ">176, c1=-133.216, c2=-123.978 g=-140.078\n",
            ">177, c1=-134.221, c2=-125.480 g=-141.194\n",
            ">178, c1=-134.698, c2=-126.118 g=-141.979\n",
            ">179, c1=-134.719, c2=-127.141 g=-143.299\n",
            ">180, c1=-135.538, c2=-127.622 g=-143.740\n",
            ">181, c1=-137.405, c2=-128.569 g=-144.916\n",
            ">182, c1=-137.594, c2=-129.024 g=-145.245\n",
            ">183, c1=-138.682, c2=-130.417 g=-146.258\n",
            ">184, c1=-138.860, c2=-129.833 g=-146.669\n",
            ">185, c1=-139.068, c2=-131.834 g=-148.213\n",
            ">186, c1=-141.203, c2=-132.203 g=-149.284\n",
            ">187, c1=-141.701, c2=-132.961 g=-149.965\n",
            ">188, c1=-142.790, c2=-133.943 g=-150.160\n",
            ">189, c1=-143.173, c2=-135.444 g=-151.444\n",
            ">190, c1=-144.055, c2=-135.326 g=-151.974\n",
            ">191, c1=-144.473, c2=-136.547 g=-153.087\n",
            ">192, c1=-146.131, c2=-137.679 g=-154.099\n",
            ">193, c1=-145.963, c2=-138.069 g=-154.917\n",
            ">194, c1=-147.055, c2=-139.026 g=-155.331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0194.png and model_0194.h5\n",
            ">195, c1=-147.110, c2=-139.894 g=-156.524\n",
            ">196, c1=-148.873, c2=-140.701 g=-157.525\n",
            ">197, c1=-149.653, c2=-141.513 g=-158.457\n",
            ">198, c1=-150.832, c2=-142.450 g=-159.286\n",
            ">199, c1=-151.408, c2=-142.361 g=-159.888\n",
            ">200, c1=-151.999, c2=-144.174 g=-160.648\n",
            ">201, c1=-152.489, c2=-145.168 g=-161.584\n",
            ">202, c1=-154.853, c2=-145.224 g=-162.384\n",
            ">203, c1=-155.363, c2=-146.976 g=-163.605\n",
            ">204, c1=-156.089, c2=-147.132 g=-164.693\n",
            ">205, c1=-156.484, c2=-147.636 g=-164.667\n",
            ">206, c1=-157.438, c2=-149.645 g=-166.016\n",
            ">207, c1=-158.001, c2=-149.572 g=-165.392\n",
            ">208, c1=-158.407, c2=-151.521 g=-167.377\n",
            ">209, c1=-159.985, c2=-152.112 g=-168.659\n",
            ">210, c1=-160.956, c2=-152.377 g=-169.292\n",
            ">211, c1=-161.516, c2=-153.766 g=-170.228\n",
            ">212, c1=-162.101, c2=-154.478 g=-171.380\n",
            ">213, c1=-162.737, c2=-154.463 g=-171.565\n",
            ">214, c1=-163.378, c2=-156.222 g=-173.086\n",
            ">215, c1=-165.070, c2=-156.221 g=-173.679\n",
            ">216, c1=-165.251, c2=-157.975 g=-174.902\n",
            ">217, c1=-166.251, c2=-157.934 g=-175.431\n",
            ">218, c1=-166.976, c2=-159.563 g=-176.339\n",
            ">219, c1=-168.749, c2=-160.415 g=-177.184\n",
            ">220, c1=-168.725, c2=-160.939 g=-177.822\n",
            ">221, c1=-170.030, c2=-162.167 g=-178.406\n",
            ">222, c1=-170.620, c2=-161.273 g=-179.287\n",
            ">223, c1=-171.199, c2=-163.587 g=-180.510\n",
            ">224, c1=-172.429, c2=-164.792 g=-181.427\n",
            ">225, c1=-173.163, c2=-165.762 g=-182.388\n",
            ">226, c1=-174.117, c2=-166.030 g=-183.165\n",
            ">227, c1=-175.028, c2=-167.456 g=-184.370\n",
            ">228, c1=-176.237, c2=-167.759 g=-185.277\n",
            ">229, c1=-176.993, c2=-168.300 g=-185.627\n",
            ">230, c1=-176.549, c2=-170.033 g=-186.871\n",
            ">231, c1=-178.589, c2=-170.101 g=-186.708\n",
            ">232, c1=-178.984, c2=-172.158 g=-188.410\n",
            ">233, c1=-178.579, c2=-172.407 g=-189.553\n",
            ">234, c1=-180.411, c2=-173.189 g=-190.474\n",
            ">235, c1=-181.632, c2=-173.406 g=-190.296\n",
            ">236, c1=-181.608, c2=-175.626 g=-191.824\n",
            ">237, c1=-183.381, c2=-175.974 g=-193.112\n",
            ">238, c1=-184.123, c2=-175.826 g=-193.877\n",
            ">239, c1=-184.521, c2=-177.107 g=-194.154\n",
            ">240, c1=-185.944, c2=-178.855 g=-195.096\n",
            ">241, c1=-187.127, c2=-180.121 g=-196.668\n",
            ">242, c1=-187.556, c2=-179.169 g=-197.116\n",
            ">243, c1=-188.037, c2=-181.384 g=-198.550\n",
            ">244, c1=-189.998, c2=-181.747 g=-199.693\n",
            ">245, c1=-189.865, c2=-181.973 g=-199.667\n",
            ">246, c1=-190.860, c2=-183.892 g=-201.222\n",
            ">247, c1=-191.497, c2=-184.141 g=-202.099\n",
            ">248, c1=-193.659, c2=-185.303 g=-203.101\n",
            ">249, c1=-193.202, c2=-185.059 g=-202.956\n",
            ">250, c1=-194.019, c2=-187.539 g=-204.360\n",
            ">251, c1=-195.636, c2=-188.215 g=-205.708\n",
            ">252, c1=-196.324, c2=-187.880 g=-206.632\n",
            ">253, c1=-196.283, c2=-189.011 g=-207.363\n",
            ">254, c1=-197.139, c2=-189.171 g=-207.781\n",
            ">255, c1=-198.799, c2=-191.505 g=-208.670\n",
            ">256, c1=-200.776, c2=-193.167 g=-210.232\n",
            ">257, c1=-199.645, c2=-192.870 g=-209.809\n",
            ">258, c1=-200.295, c2=-195.295 g=-211.637\n",
            ">259, c1=-202.765, c2=-194.518 g=-211.964\n",
            ">260, c1=-203.825, c2=-196.690 g=-213.598\n",
            ">261, c1=-204.347, c2=-195.677 g=-213.368\n",
            ">262, c1=-204.288, c2=-198.900 g=-215.586\n",
            ">263, c1=-206.812, c2=-199.382 g=-216.918\n",
            ">264, c1=-207.147, c2=-199.369 g=-216.905\n",
            ">265, c1=-207.767, c2=-201.611 g=-218.475\n",
            ">266, c1=-208.599, c2=-200.144 g=-219.270\n",
            ">267, c1=-209.531, c2=-202.300 g=-219.684\n",
            ">268, c1=-210.117, c2=-204.115 g=-221.116\n",
            ">269, c1=-211.284, c2=-203.171 g=-222.162\n",
            ">270, c1=-212.846, c2=-204.527 g=-221.278\n",
            ">271, c1=-212.246, c2=-207.543 g=-223.755\n",
            ">272, c1=-212.544, c2=-207.592 g=-224.607\n",
            ">273, c1=-215.164, c2=-208.785 g=-225.708\n",
            ">274, c1=-215.845, c2=-209.553 g=-226.513\n",
            ">275, c1=-217.837, c2=-210.926 g=-227.944\n",
            ">276, c1=-217.494, c2=-210.299 g=-227.994\n",
            ">277, c1=-219.570, c2=-212.594 g=-228.819\n",
            ">278, c1=-220.565, c2=-213.775 g=-230.686\n",
            ">279, c1=-220.221, c2=-212.555 g=-231.257\n",
            ">280, c1=-221.167, c2=-213.925 g=-232.605\n",
            ">281, c1=-220.995, c2=-213.308 g=-232.933\n",
            ">282, c1=-223.066, c2=-216.025 g=-233.515\n",
            ">283, c1=-223.113, c2=-218.173 g=-235.102\n",
            ">284, c1=-224.697, c2=-217.923 g=-236.080\n",
            ">285, c1=-225.273, c2=-218.297 g=-236.785\n",
            ">286, c1=-223.367, c2=-219.388 g=-237.610\n",
            ">287, c1=-227.698, c2=-220.228 g=-238.607\n",
            ">288, c1=-228.383, c2=-220.215 g=-237.600\n",
            ">289, c1=-228.958, c2=-224.456 g=-240.677\n",
            ">290, c1=-231.721, c2=-224.020 g=-241.867\n",
            ">291, c1=-231.271, c2=-224.823 g=-242.570\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">Saved: generated_plot_0291.png and model_0291.h5\n",
            ">292, c1=-231.173, c2=-226.002 g=-242.905\n",
            ">293, c1=-232.904, c2=-227.873 g=-244.563\n",
            ">294, c1=-234.728, c2=-226.175 g=-245.749\n",
            ">295, c1=-233.902, c2=-225.824 g=-244.742\n",
            ">296, c1=-233.663, c2=-230.232 g=-246.865\n",
            ">297, c1=-236.983, c2=-230.194 g=-248.266\n",
            ">298, c1=-237.068, c2=-229.307 g=-248.734\n",
            ">299, c1=-237.099, c2=-232.113 g=-249.978\n",
            ">300, c1=-238.614, c2=-228.361 g=-249.023\n",
            ">301, c1=-239.628, c2=-233.886 g=-251.513\n",
            ">302, c1=-240.369, c2=-231.760 g=-251.571\n",
            ">303, c1=-241.398, c2=-235.862 g=-253.025\n",
            ">304, c1=-240.086, c2=-237.068 g=-254.178\n",
            ">305, c1=-243.060, c2=-231.500 g=-254.482\n",
            ">306, c1=-241.829, c2=-235.591 g=-252.125\n",
            ">307, c1=-245.312, c2=-241.552 g=-257.210\n",
            ">308, c1=-247.914, c2=-240.008 g=-258.411\n",
            ">309, c1=-244.063, c2=-240.065 g=-257.413\n",
            ">310, c1=-248.569, c2=-243.987 g=-260.176\n",
            ">311, c1=-249.346, c2=-243.430 g=-260.948\n",
            ">312, c1=-250.383, c2=-243.081 g=-261.991\n",
            ">313, c1=-251.047, c2=-244.169 g=-262.877\n",
            ">314, c1=-250.114, c2=-243.510 g=-262.718\n",
            ">315, c1=-253.312, c2=-247.962 g=-265.167\n",
            ">316, c1=-253.004, c2=-245.770 g=-265.119\n",
            ">317, c1=-254.307, c2=-248.617 g=-266.708\n",
            ">318, c1=-253.847, c2=-249.429 g=-266.564\n",
            ">319, c1=-257.074, c2=-251.670 g=-268.969\n",
            ">320, c1=-257.526, c2=-244.756 g=-269.175\n",
            ">321, c1=-255.850, c2=-248.530 g=-268.806\n",
            ">322, c1=-257.064, c2=-253.844 g=-270.301\n",
            ">323, c1=-259.624, c2=-256.040 g=-272.380\n",
            ">324, c1=-260.042, c2=-249.595 g=-272.808\n",
            ">325, c1=-259.310, c2=-252.674 g=-273.468\n",
            ">326, c1=-260.475, c2=-255.225 g=-273.916\n",
            ">327, c1=-262.790, c2=-257.538 g=-275.265\n",
            ">328, c1=-264.426, c2=-259.372 g=-277.136\n",
            ">329, c1=-263.919, c2=-248.172 g=-275.415\n",
            ">330, c1=-264.472, c2=-259.631 g=-278.525\n",
            ">331, c1=-264.848, c2=-255.227 g=-278.509\n",
            ">332, c1=-262.271, c2=-257.531 g=-279.253\n",
            ">333, c1=-265.137, c2=-260.392 g=-279.245\n",
            ">334, c1=-269.670, c2=-264.775 g=-282.370\n",
            ">335, c1=-267.633, c2=-256.388 g=-280.651\n",
            ">336, c1=-267.834, c2=-264.690 g=-281.221\n",
            ">337, c1=-270.156, c2=-268.578 g=-285.370\n",
            ">338, c1=-272.469, c2=-265.849 g=-286.185\n",
            ">339, c1=-271.273, c2=-259.846 g=-285.745\n",
            ">340, c1=-271.482, c2=-261.379 g=-286.062\n",
            ">341, c1=-273.483, c2=-264.165 g=-286.902\n",
            ">342, c1=-273.021, c2=-265.101 g=-288.052\n",
            ">343, c1=-274.098, c2=-266.902 g=-288.691\n",
            ">344, c1=-273.142, c2=-268.506 g=-287.846\n",
            ">345, c1=-277.407, c2=-274.904 g=-291.808\n",
            ">346, c1=-276.832, c2=-266.931 g=-291.051\n",
            ">347, c1=-278.764, c2=-272.585 g=-293.728\n",
            ">348, c1=-277.938, c2=-266.312 g=-292.469\n",
            ">349, c1=-278.516, c2=-271.825 g=-294.244\n",
            ">350, c1=-280.190, c2=-268.399 g=-294.354\n",
            ">351, c1=-278.509, c2=-269.640 g=-295.228\n",
            ">352, c1=-278.640, c2=-266.247 g=-294.997\n",
            ">353, c1=-279.024, c2=-268.272 g=-295.239\n",
            ">354, c1=-280.389, c2=-270.864 g=-295.637\n",
            ">355, c1=-279.130, c2=-275.141 g=-297.126\n",
            ">356, c1=-281.707, c2=-274.238 g=-298.546\n",
            ">357, c1=-277.650, c2=-270.827 g=-298.412\n",
            ">358, c1=-279.898, c2=-271.913 g=-298.356\n",
            ">359, c1=-278.100, c2=-274.434 g=-297.673\n",
            ">360, c1=-285.371, c2=-282.775 g=-302.199\n",
            ">361, c1=-285.779, c2=-268.446 g=-301.518\n",
            ">362, c1=-278.958, c2=-261.480 g=-299.128\n",
            ">363, c1=-275.623, c2=-261.520 g=-297.144\n",
            ">364, c1=-271.982, c2=-271.156 g=-300.274\n",
            ">365, c1=-277.776, c2=-274.288 g=-301.803\n",
            ">366, c1=-269.752, c2=-257.126 g=-299.258\n",
            ">367, c1=-278.769, c2=-278.645 g=-302.148\n",
            ">368, c1=-278.472, c2=-272.361 g=-302.178\n",
            ">369, c1=-272.184, c2=-254.892 g=-299.589\n",
            ">370, c1=-266.294, c2=-254.897 g=-298.459\n",
            ">371, c1=-269.861, c2=-252.753 g=-298.770\n",
            ">372, c1=-255.005, c2=-238.654 g=-296.718\n",
            ">373, c1=-255.055, c2=-242.069 g=-296.655\n",
            ">374, c1=-261.523, c2=-252.951 g=-296.186\n",
            ">375, c1=-245.280, c2=-211.316 g=-292.080\n",
            ">376, c1=-227.026, c2=-216.132 g=-289.982\n",
            ">377, c1=-195.650, c2=-199.118 g=-288.746\n",
            ">378, c1=-191.497, c2=-163.622 g=-282.094\n",
            ">379, c1=-190.644, c2=-217.179 g=-285.087\n",
            ">380, c1=-200.047, c2=-207.335 g=-287.816\n",
            ">381, c1=-197.828, c2=-206.957 g=-286.723\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ef41cca92c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgan_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-11-8886028e4135>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(g_model, c_model, gan_model, dataset, latent_dim, n_epochs, n_batch, n_critic)\u001b[0m\n\u001b[1;32m    159\u001b[0m                         \u001b[0mc1_tmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_loss1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m                         \u001b[0;31m# generate 'fake' examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                         \u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_fake_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhalf_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                         \u001b[0;31m# update critic model weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                         \u001b[0mc_loss2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-8886028e4135>\u001b[0m in \u001b[0;36mgenerate_fake_samples\u001b[0;34m(generator, latent_dim, n_samples)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0mx_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_latent_points\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m# predict outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;31m# create class labels with 1.0 for 'fake'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1980\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1981\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1982\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1983\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1984\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    952\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 954\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    955\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2956\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2957\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2959\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1852\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1853\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1854\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1856\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    502\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 504\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    505\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kiesgY-Apdaq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}